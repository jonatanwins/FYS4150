Will solve $\mathbf{A} \mathbf{v} = \mathbf{g}$ by the Thomas Algorithm, which is a specialiced form of Gaussian elimination,   given A is a tridiagonal matrix. The derivation of the Thomas Algorithm was reviewed in the Lecture 4 \cite{lecture_notes}. The algorithm is built up of forward and backward substitution explaned below:


\begin{tcolorbox}[colback=lightgray!20, colframe=black, title=Forward Substitution]
\[
\tilde{b}_1 = b_1
\]

\[
\tilde{b}_i = b_i - \frac{a_i}{\tilde{b}_{i-1}} c_{i-1} \quad i = 2, 3, ..., n
\]

\[
\tilde{g}_1 = g_1
\]

\[
\tilde{g}_i = g_i - \frac{a_i}{\tilde{b}_{i-1}} \tilde{g}_{i-1} \quad i = 2, 3, ..., n
\]
\end{tcolorbox}


\begin{tcolorbox}[colback=lightgray!20, colframe=black, title=Back Substitution]
\[
v_n = \frac{\tilde{g}_n}{\tilde{b}_n}
\]

\[
v_i = \frac{\tilde{g}_i - c_i v_{i+1}}{\tilde{b}_i} \quad i = n-1, ..., 2, 1
\]
\end{tcolorbox}



The signature (-1,2,-1) of the tridiagonal matrix A result in every $a_i, b_i, c_i$ takes the respective values of the signature, thus -1, 2 and -1. 


Before counting floating-point operations (FLOPs) for this algorithm, will note $\frac{a_i}{\tilde{b}_{i-1}}$ is being iterated over $(n-1)$ times in both steps in the forward substitution. Will define a value $w_i = \frac{a_i}{\tilde{b}_{i-1}}$ which will reduce FLOPs by $n-1$ calculations.

Numbers of FLOPs becomes $3(n-1) +  2(n-1) = 5 (n-1)$ FLOPs for the forward substitutions and $(n-1) + 3 (n-1)$ FLOPs for the backward substitutions. This result in a total of $9(n-1)$ FLOPs for the general algorithm.


